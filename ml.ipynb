{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%logstop\n",
    "%logstart -rtq ~/.logs/ml.py append\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from static_grader import grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Miniproject\n",
    "## Introduction\n",
    "\n",
    "The objective of this miniproject is to exercise your ability to create effective machine learning models for making predictions. We will be working with nursing home inspection data from the United States, predicting which providers may be fined and for how much.\n",
    "\n",
    "## Scoring\n",
    "\n",
    "In this miniproject you will often submit your model's `predict` or `predict_proba` method to the grader. The grader will assess the performance of your model using a scoring metric, comparing it against the score of a reference model. We will use the [average precision score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html). If your model performs better than the reference solution, then you can score higher than 1.0.\n",
    "\n",
    "**Note:** If you use an estimator that relies on random draws (like a `RandomForestClassifier`) you should set the `random_state=` to an integer so that your results are reproducible. \n",
    "\n",
    "## Downloading the data\n",
    "\n",
    "We can download the data set from Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "File ‘./ml-data/providers-train.csv’ already there; not retrieving.\n",
      "\n",
      "File ‘./ml-data/providers-metadata.csv’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir data\n",
    "wget http://dataincubator-wqu.s3.amazonaws.com/mldata/providers-train.csv -nc -P ./ml-data\n",
    "wget http://dataincubator-wqu.s3.amazonaws.com/mldata/providers-metadata.csv -nc -P ./ml-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `wget` not found.\n"
     ]
    }
   ],
   "source": [
    "wget?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the data into a Pandas DataFrame. Several columns will become target labels in future questions. Let's pop those columns out from the data, and drop related columns that are neither targets nor reasonable features (i.e. we don't wouldn't know how many times a facility denied payment before knowing whether it was fined).\n",
    "\n",
    "The data has many columns. We have also provided a data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Label</th>\n",
       "      <th>Description</th>\n",
       "      <th>Format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROVNUM</td>\n",
       "      <td>Federal Provider Number</td>\n",
       "      <td>Federal Provider Number</td>\n",
       "      <td>6 alphanumeric characters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROVNAME</td>\n",
       "      <td>Provider Name</td>\n",
       "      <td>Provider Name</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>Provider Address</td>\n",
       "      <td>Provider Address</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Provider City</td>\n",
       "      <td>Provider City</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STATE</td>\n",
       "      <td>Provider State</td>\n",
       "      <td>Provider State</td>\n",
       "      <td>2-character postal abbreviation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable                    Label              Description  \\\n",
       "0   PROVNUM  Federal Provider Number  Federal Provider Number   \n",
       "1  PROVNAME            Provider Name            Provider Name   \n",
       "2   ADDRESS         Provider Address         Provider Address   \n",
       "3      CITY            Provider City            Provider City   \n",
       "4     STATE           Provider State           Provider State   \n",
       "\n",
       "                            Format  \n",
       "0        6 alphanumeric characters  \n",
       "1                             text  \n",
       "2                             text  \n",
       "3                             text  \n",
       "4  2-character postal abbreviation  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('./ml-data/providers-metadata.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./ml-data/providers-train.csv', encoding='latin1')\n",
    "\n",
    "fine_counts = data.pop('FINE_CNT')\n",
    "fine_totals = data.pop('FINE_TOT')\n",
    "cycle_2_score = data.pop('CYCLE_2_TOTAL_SCORE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        15259\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "         ...  \n",
       "13887        0\n",
       "13888        0\n",
       "13889        0\n",
       "13890        0\n",
       "13891    70865\n",
       "Name: FINE_TOT, Length: 13892, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            PROVNUM\n",
       "1           PROVNAME\n",
       "2            ADDRESS\n",
       "3               CITY\n",
       "4              STATE\n",
       "           ...      \n",
       "74          FINE_TOT\n",
       "75        PAYDEN_CNT\n",
       "76    TOT_PENLTY_CNT\n",
       "77          LOCATION\n",
       "78          FILEDATE\n",
       "Name: Variable, Length: 79, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['Variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Variable            Label      Description   Format\n",
      "73  FINE_CNT  Number of Fines  Number of Fines  integer\n"
     ]
    }
   ],
   "source": [
    "print(metadata[metadata['Variable']=='FINE_CNT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Label</th>\n",
       "      <th>Description</th>\n",
       "      <th>Format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>FINE_CNT</td>\n",
       "      <td>Number of Fines</td>\n",
       "      <td>Number of Fines</td>\n",
       "      <td>integer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Variable            Label      Description   Format\n",
       "73  FINE_CNT  Number of Fines  Number of Fines  integer"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[metadata['Variable']=='FINE_CNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(groups):\n",
    "    # default input type dataframeGroupby\n",
    "    print(groups.shape)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVNUM</th>\n",
       "      <th>PROVNAME</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>PHONE</th>\n",
       "      <th>COUNTY_SSA</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "      <th>BEDCERT</th>\n",
       "      <th>...</th>\n",
       "      <th>CERTIFICATION</th>\n",
       "      <th>CYCLE_1_DEFS</th>\n",
       "      <th>CYCLE_1_NFROMDEFS</th>\n",
       "      <th>CYCLE_1_NFROMCOMP</th>\n",
       "      <th>CYCLE_1_DEFS_SCORE</th>\n",
       "      <th>CYCLE_1_NUMREVIS</th>\n",
       "      <th>CYCLE_1_REVISIT_SCORE</th>\n",
       "      <th>CYCLE_1_TOTAL_SCORE</th>\n",
       "      <th>CYCLE_1_SURVEY_DATE</th>\n",
       "      <th>CYCLE_2_SURVEY_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PROVNUM, PROVNAME, ADDRESS, CITY, STATE, ZIP, PHONE, COUNTY_SSA, COUNTY_NAME, BEDCERT, RESTOT, INHOSP, CCRC_FACIL, SFF, CHOW_LAST_12MOS, SPRINKLER_STATUS, EXP_TOTAL, ADJ_TOTAL, OWNERSHIP, CERTIFICATION, CYCLE_1_DEFS, CYCLE_1_NFROMDEFS, CYCLE_1_NFROMCOMP, CYCLE_1_DEFS_SCORE, CYCLE_1_NUMREVIS, CYCLE_1_REVISIT_SCORE, CYCLE_1_TOTAL_SCORE, CYCLE_1_SURVEY_DATE, CYCLE_2_SURVEY_DATE]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['STATE']=='AX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        AL\n",
       "1        AL\n",
       "2        AL\n",
       "3        AL\n",
       "4        AL\n",
       "         ..\n",
       "13887    TX\n",
       "13888    TX\n",
       "13889    TX\n",
       "13890    TX\n",
       "13891    TX\n",
       "Name: STATE, Length: 13892, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['STATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AK': 15932.75,\n",
       " 'AL': 13672.320388349515,\n",
       " 'AR': 17596.6815920398,\n",
       " 'AZ': 1512.7222222222222,\n",
       " 'CA': 8054.977611940299,\n",
       " 'CO': 22112.54591836735,\n",
       " 'CT': 8438.121359223302,\n",
       " 'DC': 27333.933333333334,\n",
       " 'DE': 24899.0,\n",
       " 'FL': 16612.338211382114,\n",
       " 'GA': 29459.975,\n",
       " 'GU': 0.0,\n",
       " 'HI': 16133.309523809523,\n",
       " 'IA': 16565.303571428572,\n",
       " 'ID': 42741.942028985504,\n",
       " 'IL': 6634.197226502311,\n",
       " 'IN': 5626.954545454545,\n",
       " 'KS': 24420.79109589041,\n",
       " 'KY': 32656.315384615384,\n",
       " 'LA': 5611.819277108434,\n",
       " 'MA': 16722.25925925926,\n",
       " 'MD': 42806.67661691542,\n",
       " 'ME': 1275.5869565217392,\n",
       " 'MI': 21437.39746835443,\n",
       " 'MN': 3219.326530612245,\n",
       " 'MO': 7635.160997732426,\n",
       " 'MS': 7595.4812834224595,\n",
       " 'MT': 32754.970588235294,\n",
       " 'NC': 30445.040506329115,\n",
       " 'ND': 560.171052631579,\n",
       " 'NE': 8377.755319148937,\n",
       " 'NH': 260.45588235294116,\n",
       " 'NJ': 3490.756838905775,\n",
       " 'NM': 39652.64705882353,\n",
       " 'NV': 3050.1964285714284,\n",
       " 'NY': 2213.51526032316,\n",
       " 'OH': 8214.822977725675,\n",
       " 'OK': 11812.111111111111,\n",
       " 'OR': 12365.983606557376,\n",
       " 'PA': 9216.964686998395,\n",
       " 'PR': 13563.333333333334,\n",
       " 'RI': 3953.44,\n",
       " 'SC': 28205.171779141103,\n",
       " 'SD': 13476.666666666666,\n",
       " 'TN': 37722.919117647056,\n",
       " 'TX': 18147.119744058502,\n",
       " 'UT': 11496.727272727272,\n",
       " 'VA': 19835.32283464567,\n",
       " 'VT': 16241.14705882353,\n",
       " 'WA': 43295.230769230766,\n",
       " 'WI': 18425.87278106509,\n",
       " 'WV': 52675.85046728972,\n",
       " 'WY': 12007.057142857142}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_totals.groupby(data['STATE']).mean().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: state_model\n",
    "\n",
    "A federal agency, Centers for Medicare and Medicaid Services (CMS), imposes regulations on nursing homes. However, nursing homes are inspected by state agencies for compliance with regulations, and fines for violations can vary widely between states.\n",
    "\n",
    "Let's develop a very simple initial model to predict the amount of fines a nursing home might expect to pay based on its location. Fill in the class definition of the custom estimator, `StateMeanEstimator`, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "\n",
    "class GroupMeanEstimator(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, grouper):\n",
    "        self.grouper = grouper\n",
    "        self.group_averages = {}\n",
    "        self.global_average = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Use self.group_averages to store the average penalty by group\n",
    "        if not isinstance(X,pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        self.group_averages = y.groupby(X[self.grouper]).mean().to_dict()\n",
    "        self.global_average = y.mean()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Return a list of predicted penalties based on group of samples in X\n",
    "        if not isinstance(X,pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        return [self.group_averages.get(group,self.global_average) for group in X[self.grouper] ]\n",
    "        #return [0] * len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filling in class definition, we can create an instance of the estimator and fit it to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None, steps=[('sme', GroupMeanEstimator(grouper='STATE'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "state_model = Pipeline([\n",
    "    ('sme', GroupMeanEstimator(grouper='STATE'))\n",
    "    ])\n",
    "state_model.fit(data, fine_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVNUM</th>\n",
       "      <th>PROVNAME</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>PHONE</th>\n",
       "      <th>COUNTY_SSA</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "      <th>BEDCERT</th>\n",
       "      <th>...</th>\n",
       "      <th>CERTIFICATION</th>\n",
       "      <th>CYCLE_1_DEFS</th>\n",
       "      <th>CYCLE_1_NFROMDEFS</th>\n",
       "      <th>CYCLE_1_NFROMCOMP</th>\n",
       "      <th>CYCLE_1_DEFS_SCORE</th>\n",
       "      <th>CYCLE_1_NUMREVIS</th>\n",
       "      <th>CYCLE_1_REVISIT_SCORE</th>\n",
       "      <th>CYCLE_1_TOTAL_SCORE</th>\n",
       "      <th>CYCLE_1_SURVEY_DATE</th>\n",
       "      <th>CYCLE_2_SURVEY_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5331</th>\n",
       "      <td>225260</td>\n",
       "      <td>BLAIRE HOUSE OF MILFORD</td>\n",
       "      <td>20 CLAFLIN STREET</td>\n",
       "      <td>MILFORD</td>\n",
       "      <td>MA</td>\n",
       "      <td>1757</td>\n",
       "      <td>5084731272</td>\n",
       "      <td>170</td>\n",
       "      <td>Worcester</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>Medicare and Medicaid</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2016-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11844</th>\n",
       "      <td>495370</td>\n",
       "      <td>BRIDGEWATER HOME , INC.</td>\n",
       "      <td>302 NORTH SECOND STREET</td>\n",
       "      <td>BRIDGEWATER</td>\n",
       "      <td>VA</td>\n",
       "      <td>22812</td>\n",
       "      <td>5408282531</td>\n",
       "      <td>820</td>\n",
       "      <td>Rockingham</td>\n",
       "      <td>127</td>\n",
       "      <td>...</td>\n",
       "      <td>Medicare and Medicaid</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>2016-04-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PROVNUM                 PROVNAME                  ADDRESS         CITY  \\\n",
       "5331   225260  BLAIRE HOUSE OF MILFORD        20 CLAFLIN STREET      MILFORD   \n",
       "11844  495370  BRIDGEWATER HOME , INC.  302 NORTH SECOND STREET  BRIDGEWATER   \n",
       "\n",
       "      STATE    ZIP       PHONE  COUNTY_SSA COUNTY_NAME  BEDCERT  ...  \\\n",
       "5331     MA   1757  5084731272         170   Worcester       73  ...   \n",
       "11844    VA  22812  5408282531         820  Rockingham      127  ...   \n",
       "\n",
       "               CERTIFICATION  CYCLE_1_DEFS  CYCLE_1_NFROMDEFS  \\\n",
       "5331   Medicare and Medicaid             1                  1   \n",
       "11844  Medicare and Medicaid            12                 12   \n",
       "\n",
       "       CYCLE_1_NFROMCOMP  CYCLE_1_DEFS_SCORE  CYCLE_1_NUMREVIS  \\\n",
       "5331                   0                   4                 1   \n",
       "11844                  1                  72                 1   \n",
       "\n",
       "       CYCLE_1_REVISIT_SCORE  CYCLE_1_TOTAL_SCORE CYCLE_1_SURVEY_DATE  \\\n",
       "5331                       0                    4          2017-06-01   \n",
       "11844                      0                   72          2017-05-25   \n",
       "\n",
       "      CYCLE_2_SURVEY_DATE  \n",
       "5331           2016-05-06  \n",
       "11844          2016-04-14  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we should test that our predict method works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18425.87278106509,\n",
       " 2213.51526032316,\n",
       " 16565.303571428572,\n",
       " 7635.160997732426,\n",
       " 18147.119744058502]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_model.predict(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AK': 15932.75,\n",
       " 'AL': 13672.320388349515,\n",
       " 'AR': 17596.6815920398,\n",
       " 'AZ': 1512.7222222222222,\n",
       " 'CA': 8054.977611940299,\n",
       " 'CO': 22112.54591836735,\n",
       " 'CT': 8438.121359223302,\n",
       " 'DC': 27333.933333333334,\n",
       " 'DE': 24899.0,\n",
       " 'FL': 16612.338211382114,\n",
       " 'GA': 29459.975,\n",
       " 'GU': 0.0,\n",
       " 'HI': 16133.309523809523,\n",
       " 'IA': 16565.303571428572,\n",
       " 'ID': 42741.942028985504,\n",
       " 'IL': 6634.197226502311,\n",
       " 'IN': 5626.954545454545,\n",
       " 'KS': 24420.79109589041,\n",
       " 'KY': 32656.315384615384,\n",
       " 'LA': 5611.819277108434,\n",
       " 'MA': 16722.25925925926,\n",
       " 'MD': 42806.67661691542,\n",
       " 'ME': 1275.5869565217392,\n",
       " 'MI': 21437.39746835443,\n",
       " 'MN': 3219.326530612245,\n",
       " 'MO': 7635.160997732426,\n",
       " 'MS': 7595.4812834224595,\n",
       " 'MT': 32754.970588235294,\n",
       " 'NC': 30445.040506329115,\n",
       " 'ND': 560.171052631579,\n",
       " 'NE': 8377.755319148937,\n",
       " 'NH': 260.45588235294116,\n",
       " 'NJ': 3490.756838905775,\n",
       " 'NM': 39652.64705882353,\n",
       " 'NV': 3050.1964285714284,\n",
       " 'NY': 2213.51526032316,\n",
       " 'OH': 8214.822977725675,\n",
       " 'OK': 11812.111111111111,\n",
       " 'OR': 12365.983606557376,\n",
       " 'PA': 9216.964686998395,\n",
       " 'PR': 13563.333333333334,\n",
       " 'RI': 3953.44,\n",
       " 'SC': 28205.171779141103,\n",
       " 'SD': 13476.666666666666,\n",
       " 'TN': 37722.919117647056,\n",
       " 'TX': 18147.119744058502,\n",
       " 'UT': 11496.727272727272,\n",
       " 'VA': 19835.32283464567,\n",
       " 'VT': 16241.14705882353,\n",
       " 'WA': 43295.230769230766,\n",
       " 'WI': 18425.87278106509,\n",
       " 'WV': 52675.85046728972,\n",
       " 'WY': 12007.057142857142}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qme = GroupMeanEstimator(grouper='STATE')\n",
    "qme.fit(data, fine_totals)\n",
    "qme.group_averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what if we have data from a nursing home in a state (or territory) of the US which is not in the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14969.857687877915]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_model.predict(pd.DataFrame([{'STATE': 'AS'}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [1, 2]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'a':[1,2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your model can handle this possibility before submitting your model's predict method to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  0.9999999999999999\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "grader.score.ml__state_model(state_model.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: simple_features_model\n",
    "\n",
    "Nursing homes vary greatly in their business characteristics. Some are owned by the government or non-profits while others are run for profit. Some house a few dozen residents while others house hundreds. Some are located within hospitals and may work with more vulnerable populations. We will try to predict which facilities are fined based on their business characteristics.\n",
    "\n",
    "We'll begin with columns in our DataFrame containing numeric and boolean features. Some of the rows contain null values; estimators cannot handle null values so these must be imputed or dropped. We will create a `Pipeline` containing transformers that process these features, followed by an estimator.\n",
    "\n",
    "**Note:** When the grader checks your answer, it passes a list of dictionaries to the `predict` or `predict_proba` method of your estimator, not a DataFrame. This means that your model must work with both data types. For this reason, we've provided a custom `ColumnSelectTransformer` for you to use instead `scikit-learn`'s own `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "simple_cols = ['BEDCERT', 'RESTOT', 'INHOSP', 'CCRC_FACIL', 'SFF', 'CHOW_LAST_12MOS', 'SPRINKLER_STATUS', 'EXP_TOTAL', 'ADJ_TOTAL']\n",
    "\n",
    "class ColumnSelectTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.replaces = {} # replace missing value of each group\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "            \n",
    "        #for colone in self.columns:\n",
    "         #   if X[colone].dtypes == 'int64' or X[colone].dtypes == 'float64':\n",
    "          #      self.replaces[colone] = X[colone].mean()\n",
    "           # if X[colone].dtypes == 'bool':\n",
    "            #\\    self.replaces[colone] = X[colone].describe()['top']\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "       \n",
    "        return X[self.columns]\n",
    "        \n",
    "simple_features = Pipeline([\n",
    "    ('cst', ColumnSelectTransformer(simple_cols)),\n",
    "    ('impute',SimpleImputer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(simple_features.fit_transform(data[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVNUM</th>\n",
       "      <th>PROVNAME</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>PHONE</th>\n",
       "      <th>COUNTY_SSA</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "      <th>BEDCERT</th>\n",
       "      <th>...</th>\n",
       "      <th>CERTIFICATION</th>\n",
       "      <th>CYCLE_1_DEFS</th>\n",
       "      <th>CYCLE_1_NFROMDEFS</th>\n",
       "      <th>CYCLE_1_NFROMCOMP</th>\n",
       "      <th>CYCLE_1_DEFS_SCORE</th>\n",
       "      <th>CYCLE_1_NUMREVIS</th>\n",
       "      <th>CYCLE_1_REVISIT_SCORE</th>\n",
       "      <th>CYCLE_1_TOTAL_SCORE</th>\n",
       "      <th>CYCLE_1_SURVEY_DATE</th>\n",
       "      <th>CYCLE_2_SURVEY_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>015010</td>\n",
       "      <td>COOSA VALLEY NURSING FACILITY</td>\n",
       "      <td>315 WEST HICKORY STREET</td>\n",
       "      <td>SYLACAUGA</td>\n",
       "      <td>AL</td>\n",
       "      <td>35150</td>\n",
       "      <td>2562495604</td>\n",
       "      <td>600</td>\n",
       "      <td>Talladega</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>Medicare and Medicaid</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>2016-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>015012</td>\n",
       "      <td>HIGHLANDS HEALTH AND REHAB</td>\n",
       "      <td>380 WOODS COVE ROAD</td>\n",
       "      <td>SCOTTSBORO</td>\n",
       "      <td>AL</td>\n",
       "      <td>35768</td>\n",
       "      <td>2562183708</td>\n",
       "      <td>350</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>Medicare and Medicaid</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>2016-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>015014</td>\n",
       "      <td>EASTVIEW REHABILITATION &amp; HEALTHCARE CENTER</td>\n",
       "      <td>7755 FOURTH AVENUE SOUTH</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>AL</td>\n",
       "      <td>35206</td>\n",
       "      <td>2058330146</td>\n",
       "      <td>360</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>Medicare and Medicaid</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>2015-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>015015</td>\n",
       "      <td>PLANTATION MANOR NURSING HOME</td>\n",
       "      <td>6450 OLD TUSCALOOSA HIGHWAY   P O BOX 97</td>\n",
       "      <td>MC CALLA</td>\n",
       "      <td>AL</td>\n",
       "      <td>35111</td>\n",
       "      <td>2054776161</td>\n",
       "      <td>360</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>Medicare and Medicaid</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>2016-02-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PROVNUM                                     PROVNAME  \\\n",
       "0  015010                COOSA VALLEY NURSING FACILITY   \n",
       "1  015012                   HIGHLANDS HEALTH AND REHAB   \n",
       "2  015014  EASTVIEW REHABILITATION & HEALTHCARE CENTER   \n",
       "3  015015                PLANTATION MANOR NURSING HOME   \n",
       "\n",
       "                                    ADDRESS        CITY STATE    ZIP  \\\n",
       "0                   315 WEST HICKORY STREET   SYLACAUGA    AL  35150   \n",
       "1                       380 WOODS COVE ROAD  SCOTTSBORO    AL  35768   \n",
       "2                  7755 FOURTH AVENUE SOUTH  BIRMINGHAM    AL  35206   \n",
       "3  6450 OLD TUSCALOOSA HIGHWAY   P O BOX 97    MC CALLA    AL  35111   \n",
       "\n",
       "        PHONE  COUNTY_SSA COUNTY_NAME  BEDCERT  ...          CERTIFICATION  \\\n",
       "0  2562495604         600   Talladega       85  ...  Medicare and Medicaid   \n",
       "1  2562183708         350     Jackson       50  ...  Medicare and Medicaid   \n",
       "2  2058330146         360   Jefferson       92  ...  Medicare and Medicaid   \n",
       "3  2054776161         360   Jefferson      103  ...  Medicare and Medicaid   \n",
       "\n",
       "   CYCLE_1_DEFS  CYCLE_1_NFROMDEFS  CYCLE_1_NFROMCOMP  CYCLE_1_DEFS_SCORE  \\\n",
       "0             7                  7                  0                  36   \n",
       "1             5                  5                  0                  44   \n",
       "2             6                  6                  0                  40   \n",
       "3             2                  2                  0                  16   \n",
       "\n",
       "   CYCLE_1_NUMREVIS  CYCLE_1_REVISIT_SCORE  CYCLE_1_TOTAL_SCORE  \\\n",
       "0                 1                      0                   36   \n",
       "1                 1                      0                   44   \n",
       "2                 1                      0                   40   \n",
       "3                 1                      0                   16   \n",
       "\n",
       "  CYCLE_1_SURVEY_DATE CYCLE_2_SURVEY_DATE  \n",
       "0          2017-04-06          2016-05-26  \n",
       "1          2017-03-16          2016-02-04  \n",
       "2          2016-10-20          2015-12-30  \n",
       "3          2017-03-09          2016-02-11  \n",
       "\n",
       "[4 rows x 29 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data['RESTOT'].isnull().sum() > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The assertion below assumes the output of `noncategorical_features.fit_transform` is a `ndarray`, not a `DataFrame`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data['RESTOT'].isnull().sum() > 0\n",
    "assert not np.isnan(simple_features.fit_transform(data)).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine the `simple_features` pipeline with an estimator in a new pipeline. Fit `simple_features_model` to the data and submit `simple_features_model.predict_proba` to the grader. You may wish to use cross-validation to tune the hyperparameters of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "simple_features_model = Pipeline([\n",
    "    ('simple', simple_features),\n",
    "    # add your estimator here\n",
    "    ('est', LogisticRegression())\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('simple',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('cst',\n",
       "                                  ColumnSelectTransformer(columns=['BEDCERT',\n",
       "                                                                   'RESTOT',\n",
       "                                                                   'INHOSP',\n",
       "                                                                   'CCRC_FACIL',\n",
       "                                                                   'SFF',\n",
       "                                                                   'CHOW_LAST_12MOS',\n",
       "                                                                   'SPRINKLER_STATUS',\n",
       "                                                                   'EXP_TOTAL',\n",
       "                                                                   'ADJ_TOTAL'])),\n",
       "                                 ('impute',\n",
       "                                  SimpleImputer(add_indicator=False, copy=True,\n",
       "                                                fill_value=None,\n",
       "                                                missing_values=nan,\n",
       "                                                strategy='mean', verbose=0))],\n",
       "                          verbose=False)),\n",
       "                ('est',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_features_model.fit(data, fine_counts > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9612\n",
       "1    3000\n",
       "2     892\n",
       "3     288\n",
       "4      70\n",
       "5      24\n",
       "6       6\n",
       "Name: FINE_CNT, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_counts.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "13887    False\n",
       "13888    False\n",
       "13889    False\n",
       "13890    False\n",
       "13891     True\n",
       "Name: FINE_CNT, Length: 13892, dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_counts > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24668334 0.33161747 0.29527525 ... 0.40266376 0.36378874 0.25819655]\n",
      "==================\n",
      "Your score:  1.002750512350338\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "def positive_probability(model):\n",
    "    def predict_proba(X):\n",
    "        print(model.predict_proba(X)[:, 1])\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "    return predict_proba\n",
    "\n",
    "grader.score.ml__simple_features(positive_probability(simple_features_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'OWNERSHIP'` and `'CERTIFICATION'` columns contain categorical data. We will have to encode the categorical data into numerical features before we pass them to an estimator. Construct one or more pipelines for this purpose. Transformers such as [LabelEncoder](https://scikit-learn.org/0.19/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder) and [OneHotEncoder](https://scikit-learn.org/0.19/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) may be useful, but you may also want to define your own transformers.\n",
    "\n",
    "If you used more than one `Pipeline`, combine them with a `FeatureUnion`. As in Question 2, we will combine this with an estimator, fit it, and submit the `predict_proba` method to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "            \n",
    "    \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        #if not isinstance(X, pd.DataFrame):\n",
    "           # X = pd.DataFrame(X)\n",
    "        X = X.squeeze('columns')\n",
    "        s = X.value_counts() #data['OWNERSHIP'].value_counts()\n",
    "        d = {}\n",
    "        n = s.shape[0]\n",
    "        for i in range(n):# we built a dictionnary to replace value\n",
    "            d[s.index[i]] = s[i]\n",
    "        return X.replace(d)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "owner_onehot = Pipeline([\n",
    "    ('cst', ColumnSelectTransformer(['OWNERSHIP'])),\n",
    "     ('ohe',OneHotEncoder())\n",
    "])\n",
    "\n",
    "cert_onehot = Pipeline([\n",
    "    ('cst', ColumnSelectTransformer(['CERTIFICATION'])),\n",
    "    ('ohe',OneHotEncoder())\n",
    "])\n",
    "\n",
    "categorical_features = FeatureUnion([ \n",
    "    ('owner_onehot', owner_onehot),\n",
    "    ('cert_onehot', cert_onehot)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features.fit_transform(data).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27784"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan([True,True,2]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features.fit_transform(data).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features.fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert categorical_features.fit_transform(data).shape[0] == data.shape[0]\n",
    "assert categorical_features.fit_transform(data).dtype == np.float64\n",
    "assert not np.isnan(categorical_features.fit_transform(data).toarray()).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous question, create a model using the `categorical_features`, fit it to the data, and submit its `predict_proba` method to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "categorical_features_model = Pipeline([\n",
    "    ('categorical', categorical_features),\n",
    "    # add your estimator here\n",
    "    #('estimator', RandomForestClassifier(n_estimators=200))\n",
    "    ('estimator', GridSearchCV(RandomForestClassifier(),\n",
    "                               param_grid = {'max_depth': range(40,150,10),\n",
    "                                             'n_estimators': range(100, 200, 25)},\n",
    "                             cv=5, verbose=1\n",
    "                              ) )\n",
    "     \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gs = GridSearchCV(categorical_features_model,\n",
    " #                              param_grid = {'max_depth': range(40,110,10)},\n",
    "  #                            cv=5, verbose=1\n",
    "   #                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gs.fit(data, fine_counts > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 220 out of 220 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('categorical',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('owner_onehot',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('cst',\n",
       "                                                                  ColumnSelectTransformer(columns=['OWNERSHIP'])),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                                categories=None,\n",
       "                                                                                drop=None,\n",
       "                                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                                handle_unknown='error',\n",
       "                                                                                n_values=None,\n",
       "                                                                                sparse=True))],\n",
       "                                                          verbose=Fal...\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False),\n",
       "                              iid='warn', n_jobs=None,\n",
       "                              param_grid={'max_depth': range(40, 150, 10),\n",
       "                                          'n_estimators': range(100, 200, 25)},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features_model.fit(data, fine_counts > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ff14299310fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_features_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 220 out of 220 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('categorical',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('owner_onehot',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('cst',\n",
       "                                                                  ColumnSelectTransformer(columns=['OWNERSHIP'])),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                                categories=None,\n",
       "                                                                                drop=None,\n",
       "                                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                                handle_unknown='error',\n",
       "                                                                                n_values=None,\n",
       "                                                                                sparse=True))],\n",
       "                                                          verbose=Fal...\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False),\n",
       "                              iid='warn', n_jobs=None,\n",
       "                              param_grid={'max_depth': range(40, 150, 10),\n",
       "                                          'n_estimators': range(100, 200, 25)},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features_model.fit(data, fine_counts > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(100, 200, 25)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(100,200,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.score.ml__categorical_features(positive_probability(categorical_features_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: business_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll combine `simple_features` and `categorical_features` in a `FeatureUnion`, followed by an estimator in a `Pipeline`. You may want to optimize the hyperparameters of your estimator using cross-validation or try engineering new features (e.g. see [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)). When you've assembled and trained your model, pass the `predict_proba` method to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_features = FeatureUnion([\n",
    "    ('simple', simple_features),\n",
    "    ('categorical', categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "business_model = Pipeline([\n",
    "    ('features', business_features),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('svd',TruncatedSVD(n_components=30)),\n",
    "     #('svd',GridSearchCV(TruncatedSVD(n_components=30),\n",
    "                           #    param_grid = {'n_components': range(20,40,5)},\n",
    "                            #   cv=5, verbose=1, scoring='accuracy')),\n",
    "    \n",
    "   #('estimator', RandomForestClassifier(n_estimators = 200, min_samples_split = 100))\n",
    "    ('estimator', GridSearchCV(RandomForestClassifier(min_samples_split = 100 ),\n",
    "                               param_grid = {'max_depth': range(40,150,10),\n",
    "                                             'n_estimators': range(100, 200, 25)},\n",
    "                             cv=5, verbose=1, n_jobs = 1\n",
    "                              ) )\n",
    "    # add your estimator here\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=4)]: Done 220 out of 220 | elapsed: 26.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('simple',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('cst',\n",
       "                                                                  ColumnSelectTransformer(columns=['BEDCERT',\n",
       "                                                                                                   'RESTOT',\n",
       "                                                                                                   'INHOSP',\n",
       "                                                                                                   'CCRC_FACIL',\n",
       "                                                                                                   'SFF',\n",
       "                                                                                                   'CHOW_LAST_12MOS',\n",
       "                                                                                                   'SPRINKLER_STATUS',\n",
       "                                                                                                   'EXP_TOTAL',\n",
       "                                                                                                   'ADJ_TOTAL'])),\n",
       "                                                                 ('impute',\n",
       "                                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                                copy=True,\n",
       "                                                                                fill_value=None,\n",
       "                                                                                missing_...\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=100,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False),\n",
       "                              iid='warn', n_jobs=4,\n",
       "                              param_grid={'max_depth': range(40, 150, 10),\n",
       "                                          'n_estimators': range(100, 200, 25)},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_model.fit(data, fine_counts > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business_model.named_steps['svd'].explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business_model.score(data,fine_counts > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grader.score.ml__business_model(positive_probability(business_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: survey_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surveys reveal safety and health deficiencies at nursing homes that may indicate risk for incidents (and penalties). CMS routinely makes surveys of nursing homes. Build a model that combines the `business_features` of each facility with its cycle 1 survey results, as well as the time between the cycle 1 and cycle 2 survey to predict the cycle 2 total score.\n",
    "\n",
    "First, let's create a transformer to calculate the difference in time between the cycle 1 and cycle 2 surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "class TimedeltaTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, t1_col, t2_col):\n",
    "        self.t1_col = t1_col\n",
    "        self.t2_col = t2_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        diff = ((pd.to_datetime(X[self.t2_col]) - \n",
    "        pd.to_datetime(X[self.t1_col])).values.astype(float)).reshape(-1,1)\n",
    "        return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.658491008e+20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.sum((pd.to_datetime(data['CYCLE_2_SURVEY_DATE']) - \n",
    "        pd.to_datetime(data['CYCLE_1_SURVEY_DATE'])).values.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_date = 'CYCLE_1_SURVEY_DATE'\n",
    "cycle_2_date = 'CYCLE_2_SURVEY_DATE'\n",
    "time_feature = TimedeltaTransformer(cycle_1_date, cycle_2_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.72160e+16],\n",
       "       [-3.50784e+16],\n",
       "       [-2.54880e+16],\n",
       "       [-3.38688e+16],\n",
       "       [-3.32640e+16]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_feature.fit_transform(data)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=60)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.timedelta(minutes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we'll collect the cycle 1 survey features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_cols = ['CYCLE_1_DEFS', 'CYCLE_1_NFROMDEFS', 'CYCLE_1_NFROMCOMP',\n",
    "                'CYCLE_1_DEFS_SCORE', 'CYCLE_1_NUMREVIS',\n",
    "                'CYCLE_1_REVISIT_SCORE', 'CYCLE_1_TOTAL_SCORE']\n",
    "cycle_1_features = ColumnSelectTransformer(cycle_1_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnSelectTransformer(columns=['CYCLE_1_DEFS', 'CYCLE_1_NFROMDEFS',\n",
       "                                 'CYCLE_1_NFROMCOMP', 'CYCLE_1_DEFS_SCORE',\n",
       "                                 'CYCLE_1_NUMREVIS', 'CYCLE_1_REVISIT_SCORE',\n",
       "                                 'CYCLE_1_TOTAL_SCORE'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycle_1_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "survey_model = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('business', business_features),\n",
    "        ('survey', cycle_1_features),\n",
    "        ('time', time_feature)\n",
    "    ])),\n",
    "    # add your estimator here\n",
    "    #('rfr',RandomForestClassifier(n_estimators = 50, max_depth = 5))\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('svd',TruncatedSVD(n_components=30)),\n",
    "     #('svd',GridSearchCV(TruncatedSVD(n_components=30),\n",
    "                           #    param_grid = {'n_components': range(20,40,5)},\n",
    "                            #   cv=5, verbose=1, scoring='accuracy')),\n",
    "    \n",
    "   #('rfr', RandomForestRegressor(n_estimators=100, max_depth=20))\n",
    "    ('estimator', GridSearchCV(RandomForestRegressor(n_estimators=200),\n",
    "                             param_grid = {'min_samples_leaf': range(20,35,5)\n",
    "                                            },\n",
    "                             cv=5, verbose=1\n",
    "                              ) )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 11.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('business',\n",
       "                                                 FeatureUnion(n_jobs=None,\n",
       "                                                              transformer_list=[('simple',\n",
       "                                                                                 Pipeline(memory=None,\n",
       "                                                                                          steps=[('cst',\n",
       "                                                                                                  ColumnSelectTransformer(columns=['BEDCERT',\n",
       "                                                                                                                                   'RESTOT',\n",
       "                                                                                                                                   'INHOSP',\n",
       "                                                                                                                                   'CCRC_FACIL',\n",
       "                                                                                                                                   'SFF',\n",
       "                                                                                                                                   'CHOW_LAST_12MOS',\n",
       "                                                                                                                                   'SPRINKLER_STATUS',\n",
       "                                                                                                                                   'EXP_TOTAL',\n",
       "                                                                                                                                   'ADJ_TOTAL'])),\n",
       "                                                                                                 ('impute',\n",
       "                                                                                                  SimpleImputer...\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_samples_leaf=1,\n",
       "                                                              min_samples_split=2,\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators=200,\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=None,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False),\n",
       "                              iid='warn', n_jobs=None,\n",
       "                              param_grid={'min_samples_leaf': range(20, 35, 5)},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_model.fit(data, cycle_2_score.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12808676685799547"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_model.score(data, cycle_2_score.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45.13019259, 40.03368554, 42.31495814, 27.64015731, 36.08449903])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_model.predict(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  1.1871510789867226\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "grader.score.ml__survey_model(survey_model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2020 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
